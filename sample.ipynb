{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-09T21:35:11.328716400Z",
     "start_time": "2024-01-09T21:35:08.080718800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 98170 images belonging to 96 classes.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'FVData/validation'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 50\u001B[0m\n\u001B[0;32m     41\u001B[0m train_generator \u001B[38;5;241m=\u001B[39m train_datagen\u001B[38;5;241m.\u001B[39mflow_from_directory(\n\u001B[0;32m     42\u001B[0m     train_dir,\n\u001B[0;32m     43\u001B[0m     target_size\u001B[38;5;241m=\u001B[39mimage_size,\n\u001B[0;32m     44\u001B[0m     batch_size\u001B[38;5;241m=\u001B[39mbatch_size,\n\u001B[0;32m     45\u001B[0m     class_mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcategorical\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m     46\u001B[0m )\n\u001B[0;32m     48\u001B[0m validation_datagen \u001B[38;5;241m=\u001B[39m ImageDataGenerator(rescale\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1.\u001B[39m\u001B[38;5;241m/\u001B[39m\u001B[38;5;241m255\u001B[39m)\n\u001B[1;32m---> 50\u001B[0m validation_generator \u001B[38;5;241m=\u001B[39m validation_datagen\u001B[38;5;241m.\u001B[39mflow_from_directory(\n\u001B[0;32m     51\u001B[0m     val_dir,\n\u001B[0;32m     52\u001B[0m     target_size\u001B[38;5;241m=\u001B[39mimage_size,\n\u001B[0;32m     53\u001B[0m     batch_size\u001B[38;5;241m=\u001B[39mbatch_size,\n\u001B[0;32m     54\u001B[0m     class_mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcategorical\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m     55\u001B[0m )\n\u001B[0;32m     57\u001B[0m test_datagen \u001B[38;5;241m=\u001B[39m ImageDataGenerator(rescale\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1.\u001B[39m\u001B[38;5;241m/\u001B[39m\u001B[38;5;241m255\u001B[39m)\n\u001B[0;32m     59\u001B[0m test_generator \u001B[38;5;241m=\u001B[39m test_datagen\u001B[38;5;241m.\u001B[39mflow_from_directory(\n\u001B[0;32m     60\u001B[0m     test_dir,\n\u001B[0;32m     61\u001B[0m     target_size\u001B[38;5;241m=\u001B[39mimage_size,\n\u001B[0;32m     62\u001B[0m     batch_size\u001B[38;5;241m=\u001B[39mbatch_size,\n\u001B[0;32m     63\u001B[0m     class_mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcategorical\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m     64\u001B[0m )\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\FVProject\\Lib\\site-packages\\keras\\preprocessing\\image.py:1648\u001B[0m, in \u001B[0;36mImageDataGenerator.flow_from_directory\u001B[1;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio)\u001B[0m\n\u001B[0;32m   1562\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mflow_from_directory\u001B[39m(\n\u001B[0;32m   1563\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m   1564\u001B[0m     directory,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1578\u001B[0m     keep_aspect_ratio\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m   1579\u001B[0m ):\n\u001B[0;32m   1580\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Takes the path to a directory & generates batches of augmented data.\u001B[39;00m\n\u001B[0;32m   1581\u001B[0m \n\u001B[0;32m   1582\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1646\u001B[0m \u001B[38;5;124;03m            and `y` is a numpy array of corresponding labels.\u001B[39;00m\n\u001B[0;32m   1647\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m-> 1648\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m DirectoryIterator(\n\u001B[0;32m   1649\u001B[0m         directory,\n\u001B[0;32m   1650\u001B[0m         \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m   1651\u001B[0m         target_size\u001B[38;5;241m=\u001B[39mtarget_size,\n\u001B[0;32m   1652\u001B[0m         color_mode\u001B[38;5;241m=\u001B[39mcolor_mode,\n\u001B[0;32m   1653\u001B[0m         keep_aspect_ratio\u001B[38;5;241m=\u001B[39mkeep_aspect_ratio,\n\u001B[0;32m   1654\u001B[0m         classes\u001B[38;5;241m=\u001B[39mclasses,\n\u001B[0;32m   1655\u001B[0m         class_mode\u001B[38;5;241m=\u001B[39mclass_mode,\n\u001B[0;32m   1656\u001B[0m         data_format\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdata_format,\n\u001B[0;32m   1657\u001B[0m         batch_size\u001B[38;5;241m=\u001B[39mbatch_size,\n\u001B[0;32m   1658\u001B[0m         shuffle\u001B[38;5;241m=\u001B[39mshuffle,\n\u001B[0;32m   1659\u001B[0m         seed\u001B[38;5;241m=\u001B[39mseed,\n\u001B[0;32m   1660\u001B[0m         save_to_dir\u001B[38;5;241m=\u001B[39msave_to_dir,\n\u001B[0;32m   1661\u001B[0m         save_prefix\u001B[38;5;241m=\u001B[39msave_prefix,\n\u001B[0;32m   1662\u001B[0m         save_format\u001B[38;5;241m=\u001B[39msave_format,\n\u001B[0;32m   1663\u001B[0m         follow_links\u001B[38;5;241m=\u001B[39mfollow_links,\n\u001B[0;32m   1664\u001B[0m         subset\u001B[38;5;241m=\u001B[39msubset,\n\u001B[0;32m   1665\u001B[0m         interpolation\u001B[38;5;241m=\u001B[39minterpolation,\n\u001B[0;32m   1666\u001B[0m         dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdtype,\n\u001B[0;32m   1667\u001B[0m     )\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\FVProject\\Lib\\site-packages\\keras\\preprocessing\\image.py:563\u001B[0m, in \u001B[0;36mDirectoryIterator.__init__\u001B[1;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio, dtype)\u001B[0m\n\u001B[0;32m    561\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m classes:\n\u001B[0;32m    562\u001B[0m     classes \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m--> 563\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m subdir \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28msorted\u001B[39m(os\u001B[38;5;241m.\u001B[39mlistdir(directory)):\n\u001B[0;32m    564\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39misdir(os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(directory, subdir)):\n\u001B[0;32m    565\u001B[0m             classes\u001B[38;5;241m.\u001B[39mappend(subdir)\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [WinError 3] The system cannot find the path specified: 'FVData/validation'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from tensorflow.keras.layers import Dense,BatchNormalization\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# from PIL import Image\n",
    "\n",
    "# Define paths to the finger vein dataset directory\n",
    "data_dir = \"FVData\"\n",
    "train_dir= \"Data/FVData/train\"\n",
    "# val_dir = \"FVData/validation\"\n",
    "test_dir = \"Data/FVData/test\"\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "# train_dir, val_dir = train_test_split(os.listdir(data_dir), test_size=0.2, random_state=42)\n",
    "\n",
    "# Image preprocessing function\n",
    "def preprocess_image(img):\n",
    "    # Customize this function based on your preprocessing requirements\n",
    "    return img / 255.0  # Normalize to the range [0, 1]\n",
    "\n",
    "# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "batch_size = 32\n",
    "image_size = (224, 224)\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Additional checks\n",
    "print(\"Number of classes (training):\", len(train_generator.class_indices))\n",
    "print(\"Number of classes (validation):\", len(validation_generator.class_indices))\n",
    "print(\"Number of classes (test):\", len(test_generator.class_indices))\n",
    "\n",
    "# print(\"Number of images in validation set:\", validation_generator.samples)\n",
    "\n",
    "# Display a few images from the training generator\n",
    "print(\"Sample images from the validation set:\")\n",
    "for _ in range(3):\n",
    "    batch = validation_generator.next()\n",
    "    print(batch[0].shape, batch[1].shape)\n",
    "\n",
    "\n",
    "\n",
    "# print(len(validation_generator))\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Display a few images from the training generator\n",
    "def show_images(generator, num_images=5):\n",
    "    class_labels = list(generator.class_indices.keys())\n",
    "    batch = generator.next()\n",
    "    images, labels = batch\n",
    "\n",
    "    for i in range(num_images):\n",
    "        plt.subplot(1, num_images, i + 1)\n",
    "        plt.imshow(images[i])\n",
    "        plt.title(f\"Class: {class_labels[np.argmax(labels[i])]}\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Display images from the training generator\n",
    "show_images(train_generator, num_images=5)\n",
    "\n",
    "# Display images from the validation generator\n",
    "show_images(validation_generator, num_images=5)\n",
    "\n",
    "#Display images from test generator\n",
    "show_images(test_generator,num_images=5)\n",
    "\n",
    "# Model definition\n",
    "base_model = MobileNetV2(include_top=False, weights=\"imagenet\", input_shape=(224, 224, 3))\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    tf.keras.layers.GlobalAveragePooling2D(),\n",
    "    Dense(256, activation=\"relu\"),\n",
    "    layers.BatchNormalization(), # Additional dense layer\n",
    "    # tf.keras.layers.Dropout(0.5),  # Dropout layer for regularization\n",
    "    Dense(128, activation=\"relu\"),\n",
    "    layers.BatchNormalization(),\n",
    "    Dense(64, activation=\"relu\"),\n",
    "    layers.BatchNormalization(),\n",
    "    Dense(32, activation=\"relu\"),\n",
    "    layers.BatchNormalization(), # Additional dense layer\n",
    "    Dense(len(train_generator.class_indices), activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(optimizer= tf.keras.optimizers.Adam(learning_rate=0.0001), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Set up EarlyStopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "# Fine-tuning: Unfreeze the last 20 layers of the base model\n",
    "for layer in base_model.layers[-20:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    epochs=1,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=len(validation_generator),\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "# Evaluate the model on the test set\n",
    "test_results = model.evaluate(test_generator, steps=len(test_generator))\n",
    "print(\"Test Loss:\", test_results[0])\n",
    "print(\"Test Accuracy:\", test_results[1])\n",
    "# Example usage for predicting an unknown finger vein image\n",
    "# unknown_finger_path = \"SCUT FV Dataset/session1_ROI/session1_ROI/1/1_1_0_0_1.bmp\"\n",
    "# predicted_class = model.predict(train_datagen.flow(np.expand_dims(preprocess_image(cv2.imread(unknown_finger_path)), axis=0)))\n",
    "# print(f\"Predicted class: {predicted_class}\")\n",
    "# unknown_finger_path = \"sample_dataset/short_sample/3/3_1_0_0_1.bmp\"\n",
    "# predicted_class_probabilities = model.predict(train_datagen.flow(np.expand_dims(preprocess_image(cv2.imread(unknown_finger_path)), axis=0)))\n",
    "# # predicted_class = np.argmax(predicted_class_probabilities, axis=1)[0]\n",
    "# predicted_class_label = list(train_generator.class_indices.keys())[predicted_class]\n",
    "# print(f\"Predicted class: {predicted_class}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "88622d4fc62bc3c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-15T07:53:48.652004Z",
     "start_time": "2023-12-15T07:53:48.581937Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 33ms/step\n",
      "Predicted class: 1\n"
     ]
    }
   ],
   "source": [
    "unknown_finger_path = \"collected_final/80/80_1_0_0_1.bmp\"\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# Example usage for predicting an unknown finger vein image\n",
    "# Load and preprocess the image\n",
    "unknown_finger_img = image.load_img(unknown_finger_path, target_size=(224, 224))\n",
    "unknown_finger_img_array = image.img_to_array(unknown_finger_img)\n",
    "unknown_finger_img_array = preprocess_image(unknown_finger_img_array)\n",
    "unknown_finger_img_array = np.expand_dims(unknown_finger_img_array, axis=0)\n",
    "\n",
    "# Predict the class probabilities\n",
    "predicted_class_probabilities = model.predict(unknown_finger_img_array)\n",
    "\n",
    "# Get the predicted class index\n",
    "predicted_class_index = np.argmax(predicted_class_probabilities, axis=1)[0]\n",
    "\n",
    "# Map the class index to the actual class label using the data generator's class_indices\n",
    "class_label = list(train_generator.class_indices.keys())[predicted_class_index]\n",
    "\n",
    "print(f\"Predicted class: {class_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory: C:\\Users\\ssnfs\\DataspellProjects\\FVProject\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"Current Working Directory:\", os.getcwd())\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-15T20:03:23.193983Z",
     "start_time": "2023-12-15T20:03:23.168285200Z"
    }
   },
   "id": "dfdf8f4c37a3112f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
