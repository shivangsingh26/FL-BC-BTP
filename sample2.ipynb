{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-09T21:51:51.769811200Z",
     "start_time": "2024-01-09T21:51:37.679927100Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 98170 images belonging to 96 classes.\n",
      "Found 24518 images belonging to 96 classes.\n",
      "3068/3068 [==============================] - 205s 66ms/step\n",
      "767/767 [==============================] - 51s 67ms/step\n"
     ]
    }
   ],
   "source": [
    "# # import cv2\n",
    "# ##TODO : REMOVE VALIDATION SET- ISME convert into sets wale me dikkat aayegi\n",
    "# ##TODO : DONT USE AUGMENTED DATA ON TRAINING SET\n",
    "# ##TODO : LOOK INTO THE LAYERS WHERE ACT FUNC ARE RELU BUT IN MOBILENET V2 WE DONT USE RELU\n",
    "\n",
    "\n",
    "# import numpy as np\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.applications import MobileNetV2\n",
    "# from tensorflow.keras.layers import Dense,BatchNormalization\n",
    "# from tensorflow.keras import layers\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "# \n",
    "# # Define paths to the finger vein dataset directory\n",
    "# data_dir = \"FVData\"\n",
    "# train_dir = \"FVData/train\"\n",
    "# test_dir = \"FVData/test\"\n",
    "# \n",
    "# # Image preprocessing function\n",
    "# def preprocess_image(img):\n",
    "#     return img / 255.0  # Normalize to the range [0, 1]\n",
    "# \n",
    "# # Data generators\n",
    "# batch_size = 32\n",
    "# image_size = (224, 224)\n",
    "# \n",
    "# #ImageDataGenerator is used for normalizing the pixel values to the range [0, 1],\n",
    "# train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "# train_generator = train_datagen.flow_from_directory(\n",
    "#     train_dir,\n",
    "#     target_size=image_size,\n",
    "#     batch_size=batch_size,\n",
    "#     class_mode='categorical',\n",
    "#     shuffle=False  # Important: Set shuffle to False for feature extraction\n",
    "# )\n",
    "# \n",
    "# test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "# test_generator = test_datagen.flow_from_directory(\n",
    "#     test_dir,\n",
    "#     target_size=image_size,\n",
    "#     batch_size=batch_size,\n",
    "#     class_mode='categorical',\n",
    "#     shuffle=False  # Important: Set shuffle to False for feature extraction\n",
    "# )\n",
    "# \n",
    "# # Model definition for feature extraction with MobileNetV2 activations\n",
    "# base_model = MobileNetV2(include_top=False, weights=\"imagenet\", input_shape=(224, 224, 3))\n",
    "# \n",
    "# for layer in base_model.layers:\n",
    "#     layer.trainable = False\n",
    "# \n",
    "# model = Sequential([\n",
    "#     base_model,\n",
    "#     tf.keras.layers.GlobalAveragePooling2D(),\n",
    "#     Dense(256, activation=\"relu\"),\n",
    "#     layers.BatchNormalization(),\n",
    "#     Dense(128, activation=\"relu\"),\n",
    "#     layers.BatchNormalization(),\n",
    "#     Dense(64, activation=\"relu\"),\n",
    "#     layers.BatchNormalization()\n",
    "# ])\n",
    "# \n",
    "# # Extract features\n",
    "# train_features = model.predict(train_generator)\n",
    "# test_features = model.predict(test_generator)\n",
    "# \n",
    "# # Save the features\n",
    "# np.save(\"train_features.npy\", train_features)\n",
    "# np.save(\"test_features.npy\", test_features)\n",
    "\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Dense,BatchNormalization\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Define paths to the finger vein dataset directory\n",
    "data_dir = \"FVData\"\n",
    "train_dir = \"Data/FVData/train\"\n",
    "test_dir = \"Data/FVData/test\"\n",
    "\n",
    "# Image preprocessing function\n",
    "def preprocess_image(img):\n",
    "    return img / 255.0  # Normalize to the range [0, 1]\n",
    "\n",
    "# Data generators\n",
    "batch_size = 32\n",
    "image_size = (224, 224)\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False  # Important: Set shuffle to False for feature extraction\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False  # Important: Set shuffle to False for feature extraction\n",
    ")\n",
    "\n",
    "# Model definition for feature extraction with MobileNetV2 activations\n",
    "base_model = MobileNetV2(include_top=False, weights=\"imagenet\", input_shape=(224, 224, 3))\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    tf.keras.layers.GlobalAveragePooling2D(),\n",
    "    Dense(256, activation=\"relu\"),\n",
    "    layers.BatchNormalization(),\n",
    "    Dense(128, activation=\"relu\"),\n",
    "    layers.BatchNormalization(),\n",
    "    Dense(64, activation=\"relu\"),\n",
    "    layers.BatchNormalization()\n",
    "])\n",
    "\n",
    "# Extract features\n",
    "train_features = model.predict(train_generator)\n",
    "test_features = model.predict(test_generator)\n",
    "\n",
    "# Save the features and labels\n",
    "np.save(\"train_features.npy\", train_features)\n",
    "np.save(\"train_labels.npy\", train_generator.classes)\n",
    "np.save(\"test_features.npy\", test_features)\n",
    "np.save(\"test_labels.npy\", test_generator.classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_46 (Dense)            (None, 96)                6240      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,240\n",
      "Trainable params: 6,240\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Assuming model is your MobileNetV2-based model\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-09T22:32:33.606608900Z",
     "start_time": "2024-01-09T22:32:33.591293300Z"
    }
   },
   "id": "1b7133ae29e4c070",
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4650d8288d98e5fd",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-09T22:35:20.169184600Z",
     "start_time": "2024-01-09T22:35:19.793774100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\ssnfs\\anaconda3\\envs\\FVProject\\Lib\\site-packages\\keras\\engine\\training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\ssnfs\\anaconda3\\envs\\FVProject\\Lib\\site-packages\\keras\\engine\\training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\ssnfs\\anaconda3\\envs\\FVProject\\Lib\\site-packages\\keras\\engine\\training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\ssnfs\\anaconda3\\envs\\FVProject\\Lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\ssnfs\\anaconda3\\envs\\FVProject\\Lib\\site-packages\\keras\\engine\\training.py\", line 1109, in compute_loss\n        return self.compiled_loss(\n    File \"C:\\Users\\ssnfs\\anaconda3\\envs\\FVProject\\Lib\\site-packages\\keras\\engine\\compile_utils.py\", line 240, in __call__\n        self.build(y_pred)\n    File \"C:\\Users\\ssnfs\\anaconda3\\envs\\FVProject\\Lib\\site-packages\\keras\\engine\\compile_utils.py\", line 181, in build\n        self._losses = self._conform_to_outputs(y_pred, self._losses)\n    File \"C:\\Users\\ssnfs\\anaconda3\\envs\\FVProject\\Lib\\site-packages\\keras\\engine\\compile_utils.py\", line 60, in _conform_to_outputs\n        struct = map_to_output_names(outputs, self._output_names, struct)\n    File \"C:\\Users\\ssnfs\\anaconda3\\envs\\FVProject\\Lib\\site-packages\\keras\\engine\\compile_utils.py\", line 805, in map_to_output_names\n        raise ValueError(\n\n    ValueError: Found unexpected losses or metrics that do not correspond to any Model output: dict_keys(['dense_46', 'center_loss_layer_7']). Valid mode output names: ['activation_50', 'center_loss_layer_11']. Received struct is: {'dense_46': 'categorical_crossentropy', 'center_loss_layer_7': <function <lambda> at 0x0000024CDE7553A0>}.\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[32], line 177\u001B[0m\n\u001B[0;32m    174\u001B[0m num_epochs \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m10\u001B[39m  \u001B[38;5;66;03m# Adjust as needed\u001B[39;00m\n\u001B[0;32m    175\u001B[0m batch_size \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m32\u001B[39m  \u001B[38;5;66;03m# Adjust as needed\u001B[39;00m\n\u001B[1;32m--> 177\u001B[0m history \u001B[38;5;241m=\u001B[39m combined_model\u001B[38;5;241m.\u001B[39mfit(train_features, [tf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39mto_categorical(train_labels \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m, num_classes), train_features],\n\u001B[0;32m    178\u001B[0m                              epochs\u001B[38;5;241m=\u001B[39mnum_epochs, batch_size\u001B[38;5;241m=\u001B[39mbatch_size, verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m    180\u001B[0m \u001B[38;5;66;03m# Evaluate the model\u001B[39;00m\n\u001B[0;32m    181\u001B[0m test_preds, _ \u001B[38;5;241m=\u001B[39m combined_model\u001B[38;5;241m.\u001B[39mpredict(test_features)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\FVProject\\Lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[0;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[0;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[1;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filebfq10c4l.py:15\u001B[0m, in \u001B[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001B[1;34m(iterator)\u001B[0m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     14\u001B[0m     do_return \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m---> 15\u001B[0m     retval_ \u001B[38;5;241m=\u001B[39m ag__\u001B[38;5;241m.\u001B[39mconverted_call(ag__\u001B[38;5;241m.\u001B[39mld(step_function), (ag__\u001B[38;5;241m.\u001B[39mld(\u001B[38;5;28mself\u001B[39m), ag__\u001B[38;5;241m.\u001B[39mld(iterator)), \u001B[38;5;28;01mNone\u001B[39;00m, fscope)\n\u001B[0;32m     16\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m:\n\u001B[0;32m     17\u001B[0m     do_return \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "\u001B[1;31mValueError\u001B[0m: in user code:\n\n    File \"C:\\Users\\ssnfs\\anaconda3\\envs\\FVProject\\Lib\\site-packages\\keras\\engine\\training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\ssnfs\\anaconda3\\envs\\FVProject\\Lib\\site-packages\\keras\\engine\\training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\ssnfs\\anaconda3\\envs\\FVProject\\Lib\\site-packages\\keras\\engine\\training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\ssnfs\\anaconda3\\envs\\FVProject\\Lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\ssnfs\\anaconda3\\envs\\FVProject\\Lib\\site-packages\\keras\\engine\\training.py\", line 1109, in compute_loss\n        return self.compiled_loss(\n    File \"C:\\Users\\ssnfs\\anaconda3\\envs\\FVProject\\Lib\\site-packages\\keras\\engine\\compile_utils.py\", line 240, in __call__\n        self.build(y_pred)\n    File \"C:\\Users\\ssnfs\\anaconda3\\envs\\FVProject\\Lib\\site-packages\\keras\\engine\\compile_utils.py\", line 181, in build\n        self._losses = self._conform_to_outputs(y_pred, self._losses)\n    File \"C:\\Users\\ssnfs\\anaconda3\\envs\\FVProject\\Lib\\site-packages\\keras\\engine\\compile_utils.py\", line 60, in _conform_to_outputs\n        struct = map_to_output_names(outputs, self._output_names, struct)\n    File \"C:\\Users\\ssnfs\\anaconda3\\envs\\FVProject\\Lib\\site-packages\\keras\\engine\\compile_utils.py\", line 805, in map_to_output_names\n        raise ValueError(\n\n    ValueError: Found unexpected losses or metrics that do not correspond to any Model output: dict_keys(['dense_46', 'center_loss_layer_7']). Valid mode output names: ['activation_50', 'center_loss_layer_11']. Received struct is: {'dense_46': 'categorical_crossentropy', 'center_loss_layer_7': <function <lambda> at 0x0000024CDE7553A0>}.\n"
     ]
    }
   ],
   "source": [
    "# # unknown_finger_path = \"collected_final/2/2_1_0_0_1.bmp\"\n",
    "# # from tensorflow.keras.preprocessing import image\n",
    "# # \n",
    "# # # Example usage for predicting an unknown finger vein image\n",
    "# # # Load and preprocess the image\n",
    "# # unknown_finger_img = image.load_img(unknown_finger_path, target_size=(224, 224))\n",
    "# # unknown_finger_img_array = image.img_to_array(unknown_finger_img)\n",
    "# # unknown_finger_img_array = preprocess_image(unknown_finger_img_array)\n",
    "# # unknown_finger_img_array = np.expand_dims(unknown_finger_img_array, axis=0)\n",
    "# # \n",
    "# # # Predict the class probabilities\n",
    "# # predicted_class_probabilities = model.predict(unknown_finger_img_array)\n",
    "# # \n",
    "# # # Get the predicted class index\n",
    "# # predicted_class_index = np.argmax(predicted_class_probabilities, axis=1)[0]\n",
    "# # \n",
    "# # # Map the class index to the actual class label using the data generator's class_indices\n",
    "# # class_label = list(train_generator.class_indices.keys())[predicted_class_index]\n",
    "# # \n",
    "# # print(f\"Predicted class: {class_label}\")\n",
    "# \n",
    "# import numpy as np\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Dense, Dropout, Activation, BatchNormalization\n",
    "# from tensorflow.keras.optimizers import Adam\n",
    "# from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "# from tensorflow.keras.metrics import SparseCategoricalAccuracy\n",
    "# from tensorflow.keras import regularizers\n",
    "# \n",
    "# # Load the learned features\n",
    "# train_features = np.load(\"train_features.npy\")\n",
    "# test_features = np.load(\"test_features.npy\")\n",
    "# \n",
    "# # Load the corresponding labels\n",
    "# # Replace these paths with the actual paths to your label files\n",
    "# train_labels = np.load(\"train_labels.npy\")\n",
    "# test_labels = np.load(\"test_labels.npy\")\n",
    "# \n",
    "# # Split the data into training and validation sets\n",
    "# X_train, X_val, y_train, y_val = train_test_split(train_features, train_labels, test_size=0.2, random_state=42)\n",
    "# \n",
    "# # Define the classification model\n",
    "# classifier_model = Sequential([\n",
    "#     Dense(256, input_shape=(train_features.shape[1],), kernel_regularizer=regularizers.l2(0.01)),\n",
    "#     BatchNormalization(),\n",
    "#     Activation(\"relu\"),\n",
    "#     Dropout(0.5),\n",
    "# \n",
    "#     Dense(128, kernel_regularizer=regularizers.l2(0.01)),\n",
    "#     BatchNormalization(),\n",
    "#     Activation(\"relu\"),\n",
    "#     Dropout(0.5),\n",
    "# \n",
    "#     Dense(64, kernel_regularizer=regularizers.l2(0.01)),\n",
    "#     BatchNormalization(),\n",
    "#     Activation(\"relu\"),\n",
    "#     Dropout(0.5),\n",
    "# \n",
    "#     Dense(len(np.unique(train_labels)), activation=\"softmax\")\n",
    "# ])\n",
    "# \n",
    "# # Compile the model\n",
    "# classifier_model.compile(\n",
    "#     optimizer=Adam(learning_rate=0.0001),\n",
    "#     loss=SparseCategoricalCrossentropy(),\n",
    "#     metrics=[SparseCategoricalAccuracy()]\n",
    "# )\n",
    "# \n",
    "# # Train the classification model\n",
    "# classifier_model.fit(\n",
    "#     X_train, y_train,\n",
    "#     epochs=10,\n",
    "#     batch_size=32,\n",
    "#     validation_data=(X_val, y_val)\n",
    "# )\n",
    "# \n",
    "# # Evaluate the model on the test set\n",
    "# test_results = classifier_model.evaluate(test_features, test_labels)\n",
    "# print(\"Test Loss:\", test_results[0])\n",
    "# print(\"Test Accuracy:\", test_results[1])\n",
    "# \n",
    "# # Save the trained classifier model if needed\n",
    "# # classifier_model.save(\"finger_vein_classifier_model.h5\")\n",
    "# \n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization, Activation\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Load the extracted features and labels\n",
    "train_features = np.load(\"train_features.npy\")\n",
    "train_labels = np.load(\"train_labels.npy\")\n",
    "test_features = np.load(\"test_features.npy\")\n",
    "test_labels = np.load(\"test_labels.npy\")\n",
    "\n",
    "# Define the classifier model\n",
    "def build_classifier_model(input_dim, num_classes):\n",
    "    inputs = Input(shape=(input_dim,))\n",
    "    x = Dense(256)(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(128)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(num_classes)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    predictions = Activation(\"softmax\")(x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=predictions)\n",
    "    return model\n",
    "\n",
    "# Define the Center Loss layer\n",
    "class CenterLossLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, alpha, num_classes):\n",
    "        super(CenterLossLayer, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.centers = self.add_weight(\n",
    "            name='centers',\n",
    "            shape=(self.num_classes, input_shape[1][-1]),\n",
    "            initializer='uniform',\n",
    "            trainable=True\n",
    "        )\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        labels, features = inputs\n",
    "        labels = tf.cast(labels, dtype=tf.int32)  # Ensure labels are of integer type\n",
    "        labels = tf.reshape(labels, [-1])\n",
    "        centers_batch = tf.gather(self.centers, labels)\n",
    "        center_loss = tf.reduce_mean(tf.square(features - centers_batch))\n",
    "        return center_loss\n",
    "\n",
    "\n",
    "# Define the model with Center Loss and Cross-Entropy Loss\n",
    "num_classes = len(np.unique(train_labels))\n",
    "input_dim = train_features.shape[1]\n",
    "\n",
    "classifier_model = build_classifier_model(input_dim, num_classes)\n",
    "\n",
    "# Center Loss layer\n",
    "alpha = 0.5  # Adjust as needed\n",
    "center_loss_layer = CenterLossLayer(alpha, num_classes)([classifier_model.output, classifier_model.layers[-3].output])\n",
    "\n",
    "# Final model with both losses\n",
    "combined_model = Model(inputs=classifier_model.input, outputs=[classifier_model.output, center_loss_layer])\n",
    "\n",
    "# Compile the model\n",
    "combined_model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss={\n",
    "        'dense_46': 'categorical_crossentropy',\n",
    "        'center_loss_layer_7': lambda y_true, y_pred: y_pred\n",
    "    },\n",
    "    loss_weights={\n",
    "        'dense_3': 1.0,\n",
    "        'center_loss_layer_7': alpha\n",
    "    },\n",
    "    metrics={'dense_3': 'accuracy'}\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Training the model\n",
    "num_epochs = 10  # Adjust as needed\n",
    "batch_size = 32  # Adjust as needed\n",
    "\n",
    "history = combined_model.fit(train_features, [tf.keras.utils.to_categorical(train_labels - 1, num_classes), train_features],\n",
    "                             epochs=num_epochs, batch_size=batch_size, verbose=1)\n",
    "\n",
    "# Evaluate the model\n",
    "test_preds, _ = combined_model.predict(test_features)\n",
    "test_preds_classes = np.argmax(test_preds, axis=1) + 1  # Adding 1 to shift labels to start from 1\n",
    "\n",
    "# Calculate FAR and FRR\n",
    "conf_matrix = confusion_matrix(test_labels, test_preds_classes)\n",
    "far = conf_matrix.sum(axis=0) - np.diag(conf_matrix)\n",
    "frr = conf_matrix.sum(axis=1) - np.diag(conf_matrix)\n",
    "far = far / far.sum()\n",
    "frr = frr / frr.sum()\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(test_labels, test_preds_classes)\n",
    "\n",
    "print(\"FAR:\", far)\n",
    "print(\"FRR:\", frr)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80314208231fb2fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-09T21:59:08.846220Z",
     "start_time": "2024-01-09T21:59:08.838856900Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  1  1 ... 96 96 96]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load labels from the .npy file\n",
    "labels = np.load(\"train_labels.npy\")\n",
    "\n",
    "# Print the labels\n",
    "print(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ba32471a1895f3d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-09T22:00:04.455691Z",
     "start_time": "2024-01-09T22:00:04.438683Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.4076832  ... 0.38587716 0.         0.7504778 ]\n",
      " [0.         0.         0.40484235 ... 0.47986877 0.         0.8896746 ]\n",
      " [0.         0.         0.35770246 ... 0.6519851  0.         0.86905146]\n",
      " ...\n",
      " [0.         0.         0.17601173 ... 0.5627908  0.         0.85993886]\n",
      " [0.         0.         0.18770634 ... 0.51039445 0.         1.052765  ]\n",
      " [0.         0.         0.10082483 ... 0.5466481  0.         1.0815744 ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load labels from the .npy file\n",
    "feature = np.load(\"train_features.npy\")\n",
    "\n",
    "# Print the labels\n",
    "print(feature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373bfcba693fb62e",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
